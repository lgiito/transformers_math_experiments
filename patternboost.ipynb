{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's replicate one of the experiments in the PatternBoost paper REF. In particular, we will describe a machinery for generating maximal triangle-free graphs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a nutshell, PatternBoost is a framework for generating less trivial examples from more trivial in arbitrary mathematical domains.  The only prerequisities for setting it up are:\n",
    "\n",
    "0. Kinda unspoken prerequsite is that you are able to encode you mathematical structures of interest into computer.\n",
    "\n",
    "1. The quanitifable notion of the \"non-triviality\", here it will take a form of a reward function $r: X \\to \\mathbb R_+$, with $X$ being the set of objects of interest, which includes our original set of examples. The bigger the value of $r(x)$, the more non-trivial $x$ is.\n",
    "\n",
    "2. The \"obvious\" way how, given $x$ construct $x'$ such that $r(x) \\leq r(x')$. Usually it takes form of a greedy (not necessary deterministic) algorithm $G : X \\to X$ that tries to modify $x$ to increase its reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice the algorithm $G$ alone is not enough to come up with very non-trivial examples (examples with high reward), since in compilcated situations it performs a \"local\" optimization, rather than a \"global\" one. To compliment the local search, authors of REF suggest to use an additional generation step, which in our case will be performed by a decoder LLM. Let's sketch their approach. Fix the number of iterations $n$ and proceed as follows:\n",
    "\n",
    "Step 0. Obtain an initial dataset of examples $X_0$ (of size $k$), apply $G$ to all $x \\in X_0$, to maximize their rewards \"locally\".\n",
    "\n",
    "Step 1. Compute $r(x)$ for all $x \\in X_0$ and take the top 25% of examples in $X_0$ in terms of $r$ to obtain our first training dataset $X_0^{\\mathrm{top}}$\n",
    "\n",
    "Step 2. Train an autoregressive model $M$ on $X_0^{\\mathrm{top}}$, the model will hopefully learn some of the statistical patterns of the top examples.\n",
    "\n",
    "Step 3. Generate $k$ new examples from $M$ to obtain the new set of examples $X_1$\n",
    "\n",
    "Step 4. Repeat the process from Step 0, substituting $X_0$ with $X_1$ and so on.\n",
    "\n",
    "Step 5. Inspect $X_n$ for interesting examples with high rewards.\n",
    "\n",
    "To summarize, PatternBoost can be thought of as a certain global optimization algorithm for functions $r$ defined on sequential data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The application that we will explore in this notebook is a search of maximal triangle free graphs. Fix a number of vertices $N$ and consider "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
